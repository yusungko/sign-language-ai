{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1882d00-6fff-4968-bdb3-b98b3b98d4d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "words_list_file_path = r\"C:\\Users\\ACER\\Desktop\\wlasl\\hospital.json\"\n",
    "with open(words_list_file_path) as f:\n",
    "    words_list = json.load(f)\n",
    "print(len(words_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9734ef8-99f5-4556-a204-f639ab7f883e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "source_dir = r\"C:\\Users\\User\\Desktop\\project\\doctor (1)\\doctor\\test\"\n",
    "target_dir = r\"C:\\Users\\User\\Desktop\\project\\doctor (1)\\doctor\"\n",
    "\n",
    "# Walk through all directories and subdirectories in the source directory\n",
    "for root, dirs, files in os.walk(source_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\".mp4\"):\n",
    "            # Construct the source file path\n",
    "            source_file_path = os.path.join(root, file)\n",
    "            \n",
    "            # Construct the target file path\n",
    "            target_file_path = os.path.join(target_dir, file)\n",
    "            \n",
    "            # Move the file to the target directory\n",
    "            shutil.move(source_file_path, target_file_path)\n",
    "source_dir = r\"C:\\Users\\User\\Desktop\\project\\doctor (1)\\doctor\\val\"\n",
    "target_dir = r\"C:\\Users\\User\\Desktop\\project\\doctor (1)\\doctor\"\n",
    "\n",
    "# Walk through all directories and subdirectories in the source directory\n",
    "for root, dirs, files in os.walk(source_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\".mp4\"):\n",
    "            # Construct the source file path\n",
    "            source_file_path = os.path.join(root, file)\n",
    "            \n",
    "            # Construct the target file path\n",
    "            target_file_path = os.path.join(target_dir, file)\n",
    "            \n",
    "            # Move the file to the target directory\n",
    "            shutil.move(source_file_path, target_file_path)\n",
    "source_dir = r\"C:\\Users\\User\\Desktop\\project\\doctor (1)\\doctor\\train\"\n",
    "target_dir = r\"C:\\Users\\User\\Desktop\\project\\doctor (1)\\doctor\"\n",
    "\n",
    "# Walk through all directories and subdirectories in the source directory\n",
    "for root, dirs, files in os.walk(source_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\".mp4\"):\n",
    "            # Construct the source file path\n",
    "            source_file_path = os.path.join(root, file)\n",
    "            \n",
    "            # Construct the target file path\n",
    "            target_file_path = os.path.join(target_dir, file)\n",
    "            \n",
    "            # Move the file to the target directory\n",
    "            shutil.move(source_file_path, target_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67fcf7b7-206f-4afe-97f3-337713cfeaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import random\n",
    "import pathlib\n",
    "import itertools\n",
    "import collections\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import einops\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import imageio\n",
    "from IPython import display\n",
    "from urllib import request\n",
    "\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "494ae12a-8902-4d17-ad59-8abfe184c976",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class(fname):\n",
    "  \"\"\" Retrieve the name of the class given a filename.\n",
    "\n",
    "    Args:\n",
    "      fname: Name of the file in the UCF101 dataset.\n",
    "\n",
    "    Returns:\n",
    "      Class that the file belongs to.\n",
    "  \"\"\"\n",
    "  return fname.split('_')[0]\n",
    "def get_position(fname):\n",
    "  \"\"\" Retrieve the name of the class given a filename.\n",
    "\n",
    "    Args:\n",
    "      fname: Name of the file in the UCF101 dataset.\n",
    "\n",
    "    Returns:\n",
    "      Class that the file belongs to.\n",
    "  \"\"\"\n",
    "  try:\n",
    "      return fname.split('_')[1]\n",
    "  except:\n",
    "      return \"nope\"\n",
    "def get_files_per_class(files):\n",
    "    \"\"\" Retrieve the files that belong to each class.\n",
    "\n",
    "    Args:\n",
    "      files: List of files in the dataset.\n",
    "\n",
    "    Returns:\n",
    "      Dictionary of class names (key) and files (values). \n",
    "    \"\"\"\n",
    "    files_for_class = collections.defaultdict(list)\n",
    "    for fname in files:\n",
    "        class_name = get_class(fname)\n",
    "        files_for_class[class_name].append(fname)\n",
    "    return files_for_class\n",
    "def select_subset_of_classes(files_for_class, classes, files_per_class):\n",
    "  \"\"\" Create a dictionary with the class name and a subset of the files in that class.\n",
    "\n",
    "    Args:\n",
    "      files_for_class: Dictionary of class names (key) and files (values).\n",
    "      classes: List of classes.\n",
    "      files_per_class: Number of files per class of interest.\n",
    "\n",
    "    Returns:\n",
    "      Dictionary with class as key and list of specified number of video files in that class.\n",
    "  \"\"\"\n",
    "  files_subset = dict()\n",
    "\n",
    "  for class_name in classes:\n",
    "    class_files = files_for_class[class_name]\n",
    "    files_subset[class_name] = class_files[:files_per_class]\n",
    "\n",
    "  return files_subset\n",
    "def download_from_zip(source_dir, to_dir, file_names):\n",
    "    \"\"\" Download the contents of the zip file from the zip URL.\n",
    "\n",
    "    Args:\n",
    "      zip_url: A URL with a zip file containing data.\n",
    "      to_dir: A directory to download data to.\n",
    "      file_names: Names of files to download.\n",
    "    \"\"\"\n",
    "    for fn in tqdm.tqdm(file_names):\n",
    "        class_name = get_class(fn)\n",
    "        source_file = source_dir / fn\n",
    "        output_dir = to_dir / class_name\n",
    "        output_file = to_dir / class_name / fn\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        source_file.rename(output_file)\n",
    "def split_class_lists(files_for_class, count):\n",
    "  \"\"\" Returns the list of files belonging to a subset of data as well as the remainder of\n",
    "    files that need to be downloaded.\n",
    "    \n",
    "    Args:\n",
    "      files_for_class: Files belonging to a particular class of data.\n",
    "      count: Number of files to download.\n",
    "\n",
    "    Returns:\n",
    "      Files belonging to the subset of data and dictionary of the remainder of files that need to be downloaded.\n",
    "  \"\"\"\n",
    "  split_files = []\n",
    "  remainder = {}\n",
    "  for cls in files_for_class:\n",
    "    split_files.extend(files_for_class[cls][:count])\n",
    "    remainder[cls] = files_for_class[cls][count:]\n",
    "  return split_files, remainder\n",
    "def download_ucf_100_subset(num_classes, splits, download_dir):\n",
    "  \"\"\" Download a subset of the UCF101 dataset and split them into various parts, such as\n",
    "    training, validation, and test.\n",
    "\n",
    "    Args:\n",
    "      zip_url: A URL with a ZIP file with the data.\n",
    "      num_classes: Number of labels.\n",
    "      splits: Dictionary specifying the training, validation, test, etc. (key) division of data \n",
    "              (value is number of files per split).\n",
    "      download_dir: Directory to download data to.\n",
    "\n",
    "    Return:\n",
    "      Mapping of the directories containing the subsections of data.\n",
    "  \"\"\"\n",
    "  files = os.listdir(r\"C:\\Users\\User\\Desktop\\project\\doctor (1)\\doctor\")\n",
    "  \n",
    "  files_for_class = get_files_per_class(files)\n",
    "\n",
    "  classes = list(files_for_class.keys())[:num_classes]\n",
    "\n",
    "  for cls in classes:\n",
    "    random.shuffle(files_for_class[cls])\n",
    "    \n",
    "  # Only use the number of classes you want in the dictionary\n",
    "  files_for_class = {x: files_for_class[x] for x in classes}\n",
    "\n",
    "  dirs = {}\n",
    "  for split_name, split_count in splits.items():\n",
    "    print(split_name, \":\")\n",
    "    split_dir = download_dir / split_name\n",
    "    split_files, files_for_class = split_class_lists(files_for_class, split_count)\n",
    "    download_from_zip(download_dir, split_dir, split_files)\n",
    "    dirs[split_name] = split_dir\n",
    "\n",
    "  return dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7367c38-ddb9-4339-9714-e1b49568edfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 868/868 [00:00<00:00, 3115.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 186/186 [00:00<00:00, 2848.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 186/186 [00:00<00:00, 2827.63it/s]\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES = 62\n",
    "FILES_PER_CLASS = 20\n",
    "download_dir = pathlib.Path(r'C:\\Users\\User\\Desktop\\project\\doctor (1)\\doctor')\n",
    "subset_paths = download_ucf_100_subset(num_classes = NUM_CLASSES,\n",
    "                                       splits = {\"train\": 14, \"val\": 3, \"test\": 3},\n",
    "                                       download_dir = download_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6deb5d20-8586-487c-b150-0494d86270e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total videos: 1240\n"
     ]
    }
   ],
   "source": [
    "video_count_train = len(list(download_dir.glob('train/*/*.mp4')))\n",
    "video_count_val = len(list(download_dir.glob('val/*/*.mp4')))\n",
    "video_count_test = len(list(download_dir.glob('test/*/*.mp4')))\n",
    "video_total = video_count_train + video_count_val + video_count_test\n",
    "print(f\"Total videos: {video_total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b96124c1-4e12-468c-b0b7-a8820ea06017",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\pytorchgpu\\lib\\site-packages\\torchvision\\transforms\\_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\envs\\pytorchgpu\\lib\\site-packages\\torchvision\\transforms\\_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.io import read_video\n",
    "from torchvision.transforms import Compose, Lambda, Resize\n",
    "from torchvision.transforms._transforms_video import CenterCropVideo\n",
    "from torchvision.transforms.functional import pad\n",
    "import threading\n",
    "from queue import Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e236f41-c90c-403a-ad36-1eb14ac9e615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the normalize function at the top level\n",
    "def normalize(x):\n",
    "    return x / 255.0\n",
    "\n",
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, directory, transform=None, frames_per_clip=25, resize_dims=(224, 224)):\n",
    "        self.directory = directory\n",
    "        self.transform = transform\n",
    "        self.frames_per_clip = frames_per_clip\n",
    "        self.resize_dims = resize_dims\n",
    "        self.classes = sorted(os.listdir(directory))  # Assuming each class has its own directory\n",
    "        self.files = []\n",
    "        for class_index, _class in enumerate(self.classes):\n",
    "            class_dir = os.path.join(directory, _class)\n",
    "            self.files += [(os.path.join(class_dir, f), class_index) for f in os.listdir(class_dir)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            file_path, class_index = self.files[idx]\n",
    "            video, _, info = read_video(file_path, pts_unit='sec')\n",
    "            total_frames = video.shape[0]\n",
    "\n",
    "            # Adjust the frame dimension for interpolation\n",
    "            video = video.permute(0, 3, 1, 2)  # Change to [frames, channels, height, width]\n",
    "\n",
    "            # Resize frames to a uniform size\n",
    "            resized_video = torch.nn.functional.interpolate(video, size=self.resize_dims, mode='bilinear', align_corners=False)\n",
    "\n",
    "            frame_indices = torch.arange(0, total_frames, 5)\n",
    "\n",
    "            video = resized_video[frame_indices]\n",
    "\n",
    "            if video.size(0) > self.frames_per_clip:\n",
    "                # If more frames than needed, trim the video to keep only the required frames\n",
    "                video = video[:self.frames_per_clip]\n",
    "\n",
    "            elif video.size(0) < self.frames_per_clip:\n",
    "                # If fewer frames than needed, fill the end with black frames\n",
    "                num_missing_frames = self.frames_per_clip - video.size(0)\n",
    "                black_frames = torch.zeros(num_missing_frames, *video.shape[1:], dtype=video.dtype, device=video.device)\n",
    "                video = torch.cat((video, black_frames), dim=0)\n",
    "\n",
    "            video = video.permute(1, 0, 2, 3)  # Change back to [frames, height, width, channels]\n",
    "\n",
    "            if self.transform:\n",
    "                # Ensure your transform can handle batched frames correctly\n",
    "                video = self.transform(video)\n",
    "\n",
    "            return video, class_index\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading data at index {idx}: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9663d7cd-3feb-41bd-84e9-cfb566a411b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Compose([\n",
    "    Lambda(normalize),  # Normalize to [0,1]\n",
    "])\n",
    "\n",
    "# Initialize datasets\n",
    "train_dataset = VideoDataset(subset_paths['train'], transform=transform)\n",
    "val_dataset = VideoDataset(subset_paths['val'], transform=transform)\n",
    "test_dataset = VideoDataset(subset_paths['test'], transform=transform)\n",
    "\n",
    "# DataLoader instances\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False, num_workers=0)\n",
    "\n",
    "# batch_size = 4  # Adjust batch size as needed\n",
    "# num_threads = 2  # Adjust number of threads as needed\n",
    "# train_loader = CustomDataLoader(train_dataset, batch_size=batch_size, num_threads=num_threads)\n",
    "# val_loader = CustomDataLoader(val_dataset, batch_size=batch_size, num_threads=num_threads)\n",
    "# test_loader = CustomDataLoader(test_dataset, batch_size=batch_size, num_threads=num_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0dce2cad-30b3-4362-9c1a-284c40e308df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 15 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.io import read_video\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "\n",
    "# Your existing dataset class and normalize function seems fine for this purpose\n",
    "\n",
    "# Function to plot a single video\n",
    "def plot_video(video_tensor):\n",
    "    \"\"\"\n",
    "    Plots frames from a video tensor.\n",
    "    Assumes video_tensor is in shape [channels, frames, height, width]\n",
    "    and the pixel values are normalized between 0 and 1.\n",
    "    \"\"\"\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=video_tensor.shape[1], figsize=(15, 5))\n",
    "    for i, frame in enumerate(video_tensor.permute(1, 0, 2, 3)):  # permute frames to the front\n",
    "        axs[i].imshow(frame.permute(1, 2, 0))  # permute to [height, width, channels]\n",
    "        axs[i].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Example of how to visualize a video from the train dataset\n",
    "def show_sample(dataset):\n",
    "    # Fetch a sample from the dataset\n",
    "    video, _ = dataset[77]  # Change 0 to another index to see different samples\n",
    "    # Assuming the video is already in the right shape and normalized\n",
    "    plot_video(video)\n",
    "\n",
    "# Assuming you have initialized train_dataset somewhere as shown previously\n",
    "show_sample(train_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98a699d4-6e49-4cd4-89a7-b724cf1dc1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\pytorchgpu\\lib\\site-packages\\resnext.py:129: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  m.weight = nn.init.kaiming_normal(m.weight, mode='fan_out')\n",
      "C:\\Users\\User\\anaconda3\\envs\\pytorchgpu\\lib\\site-packages\\torch\\serialization.py:268: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10/cuda/CUDAAllocatorConfig.h:28.)\n",
      "  return torch.UntypedStorage(obj.nbytes(), device=torch.device(location))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from resnext import ResNeXt\n",
    "from resnext import ResNeXtBottleneck\n",
    "\n",
    "# Define the parameters for the ResNeXt model\n",
    "block_type = ResNeXtBottleneck  # You can use a specific type of block, such as ResNeXtBottleneck\n",
    "layers = [3, 4, 23, 3]  # Specify the number of layers in each block\n",
    "sample_size = 224  # Specify the input size of each frame/image\n",
    "sample_duration = 16  # Specify the number of frames in the input sequence\n",
    "\n",
    "# Initialize the MobileNetV2 model\n",
    "# Make sure the model architecture parameters match those of the pretrained model\n",
    "model = ResNeXt(\n",
    "    block=block_type,\n",
    "    layers=layers,\n",
    "    sample_size=sample_size,\n",
    "    sample_duration=sample_duration,\n",
    "    num_classes=27\n",
    ")\n",
    "\n",
    "state_dict = torch.load('jester_resnext_101_RGB_16_best.pth')\n",
    "\n",
    "new_state_dict = {}\n",
    "for key, value in state_dict['state_dict'].items():\n",
    "    if key.startswith('module.'):\n",
    "        new_key = key[7:]  # Remove 'module.' prefix\n",
    "        new_state_dict[new_key] = value\n",
    "    else:\n",
    "        new_state_dict[key] = value\n",
    "\n",
    "# Load the state dictionary into the model\n",
    "model.load_state_dict(new_state_dict)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(4096, 4096),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(4096),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(4096, 8192),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(8192),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(8192, 62),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86bb0415-6feb-489b-9082-69b2c49ebfe9",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (2x9216 and 18432x2048)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchsummary\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m summary\n\u001b[0;32m      2\u001b[0m input_size \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m25\u001b[39m, \u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorchgpu\\lib\\site-packages\\torchsummary\\torchsummary.py:72\u001b[0m, in \u001b[0;36msummary\u001b[1;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[0;32m     68\u001b[0m model\u001b[38;5;241m.\u001b[39mapply(register_hook)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# make a forward pass\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# print(x.shape)\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# remove these hooks\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m hooks:\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorchgpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorchgpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorchgpu\\lib\\site-packages\\resnext.py:180\u001b[0m, in \u001b[0;36mResNeXt.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    175\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer4(x)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;66;03m# x = self.avgpool(x)\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \n\u001b[0;32m    179\u001b[0m \u001b[38;5;66;03m# x = x.view(x.size(0), -1)\u001b[39;00m\n\u001b[1;32m--> 180\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorchgpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorchgpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorchgpu\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorchgpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorchgpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1561\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1558\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[0;32m   1559\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[1;32m-> 1561\u001b[0m result \u001b[38;5;241m=\u001b[39m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[0;32m   1563\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[0;32m   1564\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[0;32m   1565\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[0;32m   1566\u001b[0m     ):\n\u001b[0;32m   1567\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorchgpu\\lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (2x9216 and 18432x2048)"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "input_size = (3, 25, 224, 224)\n",
    "\n",
    "summary(model.cuda(), input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77feb1ee-251c-4a97-bfe0-e81a58ea3ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNeXt(\n",
       "  (conv1): Conv3d(3, 64, kernel_size=(7, 7, 7), stride=(1, 2, 2), padding=(3, 3, 3), bias=False)\n",
       "  (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool3d(kernel_size=(3, 3, 3), stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): ResNeXtBottleneck(\n",
       "      (conv1): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResNeXtBottleneck(\n",
       "      (conv1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): ResNeXtBottleneck(\n",
       "      (conv1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): ResNeXtBottleneck(\n",
       "      (conv1): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResNeXtBottleneck(\n",
       "      (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): ResNeXtBottleneck(\n",
       "      (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): ResNeXtBottleneck(\n",
       "      (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): ResNeXtBottleneck(\n",
       "      (conv1): Conv3d(512, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "        (1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResNeXtBottleneck(\n",
       "      (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): ResNeXtBottleneck(\n",
       "      (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): ResNeXtBottleneck(\n",
       "      (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): ResNeXtBottleneck(\n",
       "      (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): ResNeXtBottleneck(\n",
       "      (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): ResNeXtBottleneck(\n",
       "      (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (7): ResNeXtBottleneck(\n",
       "      (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (8): ResNeXtBottleneck(\n",
       "      (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (9): ResNeXtBottleneck(\n",
       "      (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (10): ResNeXtBottleneck(\n",
       "      (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (11): ResNeXtBottleneck(\n",
       "      (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (12): ResNeXtBottleneck(\n",
       "      (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (13): ResNeXtBottleneck(\n",
       "      (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (14): ResNeXtBottleneck(\n",
       "      (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (15): ResNeXtBottleneck(\n",
       "      (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (16): ResNeXtBottleneck(\n",
       "      (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (17): ResNeXtBottleneck(\n",
       "      (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (18): ResNeXtBottleneck(\n",
       "      (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (19): ResNeXtBottleneck(\n",
       "      (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (20): ResNeXtBottleneck(\n",
       "      (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (21): ResNeXtBottleneck(\n",
       "      (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (22): ResNeXtBottleneck(\n",
       "      (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): ResNeXtBottleneck(\n",
       "      (conv1): Conv3d(1024, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "        (1): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResNeXtBottleneck(\n",
       "      (conv1): Conv3d(2048, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): ResNeXtBottleneck(\n",
       "      (conv1): Conv3d(2048, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool3d(kernel_size=(1, 7, 7), stride=1, padding=0)\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.2, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=8192, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): BatchNorm1d(8192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.2, inplace=False)\n",
       "    (8): Linear(in_features=8192, out_features=62, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51dc1a17-d0ae-4a3c-8964-36d8ad1fefb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/434 [00:00<?, ?it/s]C:\\Users\\User\\anaconda3\\envs\\pytorchgpu\\lib\\site-packages\\torch\\nn\\modules\\conv.py:605: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n",
      "  return F.conv3d(\n",
      "100%|██████████| 434/434 [07:51<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:31<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:49<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:49<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "training_loss: 4.2781  training_accuracy: 0.04  validation_loss: 4.1803 validation_accuracy: 0.027\n",
      "\n",
      "Epoch 2/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:29<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:31<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:48<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:49<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2\n",
      "training_loss: 4.0937  training_accuracy: 0.073  validation_loss: 4.0844 validation_accuracy: 0.022\n",
      "\n",
      "Epoch 3/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:30<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:32<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:50<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:49<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3\n",
      "training_loss: 4.0335  training_accuracy: 0.105  validation_loss: 3.9538 validation_accuracy: 0.048\n",
      "\n",
      "Epoch 4/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:33<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:33<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:49<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:49<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4\n",
      "training_loss: 3.9268  training_accuracy: 0.138  validation_loss: 3.9084 validation_accuracy: 0.054\n",
      "\n",
      "Epoch 5/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:31<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:33<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:49<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:49<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5\n",
      "training_loss: 3.8469  training_accuracy: 0.167  validation_loss: 3.8375 validation_accuracy: 0.081\n",
      "\n",
      "Epoch 6/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:32<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:32<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:49<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:49<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6\n",
      "training_loss: 3.7973  training_accuracy: 0.196  validation_loss: 3.8178 validation_accuracy: 0.091\n",
      "\n",
      "Epoch 7/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:31<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:33<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:49<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:49<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7\n",
      "training_loss: 3.7745  training_accuracy: 0.181  validation_loss: 3.9141 validation_accuracy: 0.07\n",
      "\n",
      "Epoch 8/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:32<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:32<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:49<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:49<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8\n",
      "training_loss: 3.7332  training_accuracy: 0.195  validation_loss: 3.8067 validation_accuracy: 0.102\n",
      "\n",
      "Epoch 9/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:33<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:45<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:52<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:52<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9\n",
      "training_loss: 3.7117  training_accuracy: 0.206  validation_loss: 3.8339 validation_accuracy: 0.134\n",
      "\n",
      "Epoch 10/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:43<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:46<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:53<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:52<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10\n",
      "training_loss: 3.6742  training_accuracy: 0.206  validation_loss: 3.7111 validation_accuracy: 0.108\n",
      "\n",
      "Epoch 11/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:42<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:45<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:52<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:52<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11\n",
      "training_loss: 3.671  training_accuracy: 0.214  validation_loss: 3.6868 validation_accuracy: 0.097\n",
      "\n",
      "Epoch 12/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:42<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:45<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:52<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:52<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12\n",
      "training_loss: 3.6767  training_accuracy: 0.236  validation_loss: 3.6706 validation_accuracy: 0.113\n",
      "\n",
      "Epoch 13/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:42<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:45<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:52<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:52<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13\n",
      "training_loss: 3.6862  training_accuracy: 0.237  validation_loss: 3.723 validation_accuracy: 0.129\n",
      "\n",
      "Epoch 14/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:42<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:45<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:53<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:53<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14\n",
      "training_loss: 3.6904  training_accuracy: 0.203  validation_loss: 3.7705 validation_accuracy: 0.097\n",
      "\n",
      "Epoch 15/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:43<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:46<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:52<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:52<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15\n",
      "training_loss: 3.6527  training_accuracy: 0.25  validation_loss: 3.7233 validation_accuracy: 0.118\n",
      "\n",
      "Epoch 16/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:48<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [08:24<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [02:02<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [02:02<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16\n",
      "training_loss: 3.6572  training_accuracy: 0.242  validation_loss: 3.7395 validation_accuracy: 0.113\n",
      "\n",
      "Epoch 17/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [08:36<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [08:15<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [02:01<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [02:07<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17\n",
      "training_loss: 3.6318  training_accuracy: 0.252  validation_loss: 3.7185 validation_accuracy: 0.108\n",
      "\n",
      "Epoch 18/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [08:23<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [08:37<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [02:06<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [02:04<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18\n",
      "training_loss: 3.5948  training_accuracy: 0.259  validation_loss: 3.6893 validation_accuracy: 0.129\n",
      "\n",
      "Epoch 19/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [08:28<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [08:16<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:55<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:56<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19\n",
      "training_loss: 3.6022  training_accuracy: 0.25  validation_loss: 3.7265 validation_accuracy: 0.113\n",
      "\n",
      "Epoch 20/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [08:05<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [08:07<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:57<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:57<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20\n",
      "training_loss: 3.5948  training_accuracy: 0.257  validation_loss: 3.6685 validation_accuracy: 0.102\n",
      "\n",
      "Epoch 21/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [08:08<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [08:07<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:57<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:57<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21\n",
      "training_loss: 3.5819  training_accuracy: 0.278  validation_loss: 3.6372 validation_accuracy: 0.097\n",
      "\n",
      "Epoch 22/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [08:07<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [08:05<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:57<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:57<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22\n",
      "training_loss: 3.5674  training_accuracy: 0.242  validation_loss: 3.7418 validation_accuracy: 0.124\n",
      "\n",
      "Epoch 23/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [08:07<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [08:29<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [02:03<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [02:02<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23\n",
      "training_loss: 3.5992  training_accuracy: 0.258  validation_loss: 3.7742 validation_accuracy: 0.097\n",
      "\n",
      "Epoch 24/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [08:31<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [08:44<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [02:28<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [02:26<00:00,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24\n",
      "training_loss: 3.6136  training_accuracy: 0.25  validation_loss: 3.7197 validation_accuracy: 0.118\n",
      "\n",
      "Epoch 25/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [10:08<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [10:01<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [02:22<00:00,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [02:30<00:00,  1.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25\n",
      "training_loss: 3.4997  training_accuracy: 0.268  validation_loss: 3.7693 validation_accuracy: 0.14\n",
      "\n",
      "Epoch 26/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [10:13<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [10:05<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [02:29<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [02:17<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26\n",
      "training_loss: 3.5379  training_accuracy: 0.256  validation_loss: 3.8885 validation_accuracy: 0.118\n",
      "\n",
      "Epoch 27/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [10:36<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [10:33<00:00,  1.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [02:28<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [02:29<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27\n",
      "training_loss: 3.5443  training_accuracy: 0.287  validation_loss: 3.6995 validation_accuracy: 0.091\n",
      "\n",
      "Epoch 28/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [09:59<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [09:10<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [02:12<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [02:11<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28\n",
      "training_loss: 3.5155  training_accuracy: 0.278  validation_loss: 3.7156 validation_accuracy: 0.129\n",
      "\n",
      "Epoch 29/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [09:23<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [09:02<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [02:11<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [02:12<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29\n",
      "training_loss: 3.4987  training_accuracy: 0.272  validation_loss: 3.7382 validation_accuracy: 0.113\n",
      "\n",
      "Epoch 30/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [09:14<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [09:02<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [02:05<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [02:02<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30\n",
      "training_loss: 3.5316  training_accuracy: 0.267  validation_loss: 3.6811 validation_accuracy: 0.134\n",
      "\n",
      "Epoch 31/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [09:39<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [09:44<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [02:17<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [02:13<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31\n",
      "training_loss: 3.5433  training_accuracy: 0.268  validation_loss: 3.7068 validation_accuracy: 0.108\n",
      "\n",
      "Epoch 32/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:39<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:31<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:50<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:49<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32\n",
      "training_loss: 3.4978  training_accuracy: 0.236  validation_loss: 3.8377 validation_accuracy: 0.081\n",
      "\n",
      "Epoch 33/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:29<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:35<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:48<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:48<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33\n",
      "training_loss: 3.5461  training_accuracy: 0.263  validation_loss: 3.7099 validation_accuracy: 0.102\n",
      "\n",
      "Epoch 34/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:21<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:20<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:47<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:47<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34\n",
      "training_loss: 3.5026  training_accuracy: 0.257  validation_loss: 3.7985 validation_accuracy: 0.118\n",
      "\n",
      "Epoch 35/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:27<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:22<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:48<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:48<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35\n",
      "training_loss: 3.5311  training_accuracy: 0.271  validation_loss: 3.7573 validation_accuracy: 0.113\n",
      "\n",
      "Epoch 36/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:22<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:22<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:46<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:48<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36\n",
      "training_loss: 3.4917  training_accuracy: 0.265  validation_loss: 3.7365 validation_accuracy: 0.113\n",
      "\n",
      "Epoch 37/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:19<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:27<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:47<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:47<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37\n",
      "training_loss: 3.487  training_accuracy: 0.278  validation_loss: 3.7248 validation_accuracy: 0.124\n",
      "\n",
      "Epoch 38/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:20<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:26<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:47<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:46<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38\n",
      "training_loss: 3.4829  training_accuracy: 0.293  validation_loss: 3.7098 validation_accuracy: 0.129\n",
      "\n",
      "Epoch 39/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:20<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:27<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:47<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:46<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39\n",
      "training_loss: 3.4573  training_accuracy: 0.274  validation_loss: 3.7065 validation_accuracy: 0.118\n",
      "\n",
      "Epoch 40/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:22<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:21<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:47<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:47<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40\n",
      "training_loss: 3.5666  training_accuracy: 0.256  validation_loss: 3.8936 validation_accuracy: 0.075\n",
      "\n",
      "Epoch 41/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:20<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:22<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:47<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:47<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41\n",
      "training_loss: 3.4794  training_accuracy: 0.304  validation_loss: 3.6689 validation_accuracy: 0.14\n",
      "\n",
      "Epoch 42/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:21<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:26<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:46<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:46<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42\n",
      "training_loss: 3.4585  training_accuracy: 0.288  validation_loss: 3.7074 validation_accuracy: 0.102\n",
      "\n",
      "Epoch 43/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:21<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:22<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:47<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:47<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43\n",
      "training_loss: 3.4622  training_accuracy: 0.26  validation_loss: 3.8548 validation_accuracy: 0.091\n",
      "\n",
      "Epoch 44/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:20<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:25<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:47<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:47<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44\n",
      "training_loss: 3.5158  training_accuracy: 0.268  validation_loss: 3.7702 validation_accuracy: 0.097\n",
      "\n",
      "Epoch 45/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:19<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:22<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:47<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:47<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45\n",
      "training_loss: 3.4187  training_accuracy: 0.293  validation_loss: 3.7337 validation_accuracy: 0.113\n",
      "\n",
      "Epoch 46/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:20<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:23<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:49<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:47<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 46\n",
      "training_loss: 3.4475  training_accuracy: 0.251  validation_loss: 3.8087 validation_accuracy: 0.102\n",
      "\n",
      "Epoch 47/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:23<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:25<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:47<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:47<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47\n",
      "training_loss: 3.4745  training_accuracy: 0.286  validation_loss: 3.7269 validation_accuracy: 0.129\n",
      "\n",
      "Epoch 48/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:23<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:24<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:47<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:47<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48\n",
      "training_loss: 3.4506  training_accuracy: 0.29  validation_loss: 3.7534 validation_accuracy: 0.113\n",
      "\n",
      "Epoch 49/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:22<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:23<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:47<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:47<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 49\n",
      "training_loss: 3.4516  training_accuracy: 0.31  validation_loss: 3.6949 validation_accuracy: 0.14\n",
      "\n",
      "Epoch 50/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:21<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:22<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:48<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:47<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50\n",
      "training_loss: 3.4621  training_accuracy: 0.296  validation_loss: 3.6352 validation_accuracy: 0.129\n",
      "\n",
      "Epoch 51/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:22<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:24<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:47<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:48<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 51\n",
      "training_loss: 3.3949  training_accuracy: 0.302  validation_loss: 3.6652 validation_accuracy: 0.124\n",
      "\n",
      "Epoch 52/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:26<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:25<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:47<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:47<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 52\n",
      "training_loss: 3.4173  training_accuracy: 0.302  validation_loss: 3.6619 validation_accuracy: 0.129\n",
      "\n",
      "Epoch 53/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:23<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:23<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:48<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:47<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 53\n",
      "training_loss: 3.5041  training_accuracy: 0.305  validation_loss: 3.6712 validation_accuracy: 0.161\n",
      "\n",
      "Epoch 54/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:23<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:27<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:49<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:50<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 54\n",
      "training_loss: 3.4334  training_accuracy: 0.272  validation_loss: 3.7136 validation_accuracy: 0.108\n",
      "\n",
      "Epoch 55/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:48<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:48<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:52<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:52<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 55\n",
      "training_loss: 3.4431  training_accuracy: 0.294  validation_loss: 3.5681 validation_accuracy: 0.156\n",
      "\n",
      "Epoch 56/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:40<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:50<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:52<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:52<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56\n",
      "training_loss: 3.4523  training_accuracy: 0.316  validation_loss: 3.6518 validation_accuracy: 0.156\n",
      "\n",
      "Epoch 57/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:53<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:55<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:51<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:49<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 57\n",
      "training_loss: 3.4528  training_accuracy: 0.297  validation_loss: 3.6736 validation_accuracy: 0.151\n",
      "\n",
      "Epoch 58/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:28<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:28<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:48<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:48<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 58\n",
      "training_loss: 3.4675  training_accuracy: 0.282  validation_loss: 3.6324 validation_accuracy: 0.129\n",
      "\n",
      "Epoch 59/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:28<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:31<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:48<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:48<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 59\n",
      "training_loss: 3.4426  training_accuracy: 0.317  validation_loss: 3.5631 validation_accuracy: 0.156\n",
      "\n",
      "Epoch 60/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:26<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:29<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:49<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:49<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 60\n",
      "training_loss: 3.4174  training_accuracy: 0.3  validation_loss: 3.6422 validation_accuracy: 0.102\n",
      "\n",
      "Epoch 61/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:26<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:31<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:49<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:48<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 61\n",
      "training_loss: 3.3976  training_accuracy: 0.304  validation_loss: 3.6778 validation_accuracy: 0.129\n",
      "\n",
      "Epoch 62/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:24<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:26<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:48<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:48<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62\n",
      "training_loss: 3.4  training_accuracy: 0.3  validation_loss: 3.6283 validation_accuracy: 0.108\n",
      "\n",
      "Epoch 63/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:25<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:27<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:48<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:47<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 63\n",
      "training_loss: 3.365  training_accuracy: 0.304  validation_loss: 3.6305 validation_accuracy: 0.156\n",
      "\n",
      "Epoch 64/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:26<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:29<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:48<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:48<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 64\n",
      "training_loss: 3.3879  training_accuracy: 0.288  validation_loss: 3.7073 validation_accuracy: 0.091\n",
      "\n",
      "Epoch 65/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:26<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:28<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:48<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:48<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 65\n",
      "training_loss: 3.3896  training_accuracy: 0.32  validation_loss: 3.6346 validation_accuracy: 0.14\n",
      "\n",
      "Epoch 66/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:25<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:27<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:48<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:48<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66\n",
      "training_loss: 3.4056  training_accuracy: 0.303  validation_loss: 3.6072 validation_accuracy: 0.151\n",
      "\n",
      "Epoch 67/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:27<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:28<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:48<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:48<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 67\n",
      "training_loss: 3.4212  training_accuracy: 0.304  validation_loss: 3.6921 validation_accuracy: 0.113\n",
      "\n",
      "Epoch 68/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:25<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:28<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:47<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:47<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68\n",
      "training_loss: 3.3739  training_accuracy: 0.317  validation_loss: 3.6353 validation_accuracy: 0.145\n",
      "\n",
      "Epoch 69/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:26<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:45<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:55<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:55<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 69\n",
      "training_loss: 3.4536  training_accuracy: 0.281  validation_loss: 3.6522 validation_accuracy: 0.129\n",
      "\n",
      "Epoch 70/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:56<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:56<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:55<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:55<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 70\n",
      "training_loss: 3.4292  training_accuracy: 0.311  validation_loss: 3.6439 validation_accuracy: 0.177\n",
      "\n",
      "Epoch 71/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:37<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:29<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:49<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:49<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 71\n",
      "training_loss: 3.3872  training_accuracy: 0.301  validation_loss: 3.7478 validation_accuracy: 0.14\n",
      "\n",
      "Epoch 72/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [08:01<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [08:06<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:56<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:54<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72\n",
      "training_loss: 3.4228  training_accuracy: 0.293  validation_loss: 3.7196 validation_accuracy: 0.113\n",
      "\n",
      "Epoch 73/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [08:00<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [08:00<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:58<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:55<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 73\n",
      "training_loss: 3.4334  training_accuracy: 0.285  validation_loss: 3.6792 validation_accuracy: 0.129\n",
      "\n",
      "Epoch 74/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [08:02<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:48<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:54<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:53<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74\n",
      "training_loss: 3.4495  training_accuracy: 0.283  validation_loss: 3.6506 validation_accuracy: 0.129\n",
      "\n",
      "Epoch 75/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:45<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:47<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:52<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:53<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 75\n",
      "training_loss: 3.3706  training_accuracy: 0.297  validation_loss: 3.679 validation_accuracy: 0.145\n",
      "\n",
      "Epoch 76/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:44<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:47<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:53<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:53<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 76\n",
      "training_loss: 3.4521  training_accuracy: 0.315  validation_loss: 3.7504 validation_accuracy: 0.129\n",
      "\n",
      "Epoch 77/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:46<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:48<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:53<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:52<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 77\n",
      "training_loss: 3.4305  training_accuracy: 0.293  validation_loss: 3.751 validation_accuracy: 0.124\n",
      "\n",
      "Epoch 78/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:47<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:48<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:52<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:52<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78\n",
      "training_loss: 3.4144  training_accuracy: 0.3  validation_loss: 3.7407 validation_accuracy: 0.134\n",
      "\n",
      "Epoch 79/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:46<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:46<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:53<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:53<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 79\n",
      "training_loss: 3.41  training_accuracy: 0.338  validation_loss: 3.6902 validation_accuracy: 0.151\n",
      "\n",
      "Epoch 80/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:47<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:47<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:52<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:53<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80\n",
      "training_loss: 3.4611  training_accuracy: 0.289  validation_loss: 3.73 validation_accuracy: 0.145\n",
      "\n",
      "Epoch 81/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:48<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:46<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:52<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:53<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 81\n",
      "training_loss: 3.3972  training_accuracy: 0.317  validation_loss: 3.5879 validation_accuracy: 0.134\n",
      "\n",
      "Epoch 82/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:46<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:47<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:52<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:52<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 82\n",
      "training_loss: 3.3439  training_accuracy: 0.282  validation_loss: 3.7718 validation_accuracy: 0.145\n",
      "\n",
      "Epoch 83/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:49<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [07:57<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:56<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:58<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 83\n",
      "training_loss: 3.3946  training_accuracy: 0.316  validation_loss: 3.7611 validation_accuracy: 0.14\n",
      "\n",
      "Epoch 84/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [08:04<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [08:58<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [02:13<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [02:12<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84\n",
      "training_loss: 3.3614  training_accuracy: 0.295  validation_loss: 3.6883 validation_accuracy: 0.134\n",
      "\n",
      "Epoch 85/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [09:21<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [09:48<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [02:24<00:00,  1.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [02:15<00:00,  1.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 85\n",
      "training_loss: 3.4037  training_accuracy: 0.313  validation_loss: 3.6487 validation_accuracy: 0.129\n",
      "\n",
      "Epoch 86/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [09:23<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [09:40<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [02:29<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [02:25<00:00,  1.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86\n",
      "training_loss: 3.4162  training_accuracy: 0.308  validation_loss: 3.6312 validation_accuracy: 0.151\n",
      "\n",
      "Epoch 87/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [09:27<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [08:57<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [02:09<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [02:09<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 87\n",
      "training_loss: 3.3941  training_accuracy: 0.296  validation_loss: 3.873 validation_accuracy: 0.156\n",
      "\n",
      "Epoch 88/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [09:02<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [09:20<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [02:20<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [02:17<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 88\n",
      "training_loss: 3.3602  training_accuracy: 0.289  validation_loss: 3.7408 validation_accuracy: 0.129\n",
      "\n",
      "Epoch 89/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [08:33<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [08:15<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [02:01<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:58<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 89\n",
      "training_loss: 3.3891  training_accuracy: 0.286  validation_loss: 3.7907 validation_accuracy: 0.124\n",
      "\n",
      "Epoch 90/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [08:18<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [08:11<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:59<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:59<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90\n",
      "training_loss: 3.4016  training_accuracy: 0.303  validation_loss: 3.7951 validation_accuracy: 0.113\n",
      "\n",
      "Epoch 91/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [08:16<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [08:14<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:58<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:58<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 91\n",
      "training_loss: 3.3873  training_accuracy: 0.287  validation_loss: 3.7769 validation_accuracy: 0.108\n",
      "\n",
      "Epoch 92/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [08:13<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [08:23<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [02:01<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [02:02<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92\n",
      "training_loss: 3.3667  training_accuracy: 0.31  validation_loss: 3.7133 validation_accuracy: 0.118\n",
      "\n",
      "Epoch 93/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [08:24<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [08:28<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [02:03<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [02:02<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 93\n",
      "training_loss: 3.4542  training_accuracy: 0.35  validation_loss: 3.6341 validation_accuracy: 0.167\n",
      "\n",
      "Epoch 94/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [08:27<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [08:25<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [02:03<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [02:02<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 94\n",
      "training_loss: 3.3758  training_accuracy: 0.302  validation_loss: 3.6846 validation_accuracy: 0.134\n",
      "\n",
      "Epoch 95/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [08:27<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [08:29<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [02:02<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [02:03<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 95\n",
      "training_loss: 3.3731  training_accuracy: 0.333  validation_loss: 3.6469 validation_accuracy: 0.145\n",
      "\n",
      "Epoch 96/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [08:28<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [08:26<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:59<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:59<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96\n",
      "training_loss: 3.3416  training_accuracy: 0.315  validation_loss: 3.6922 validation_accuracy: 0.134\n",
      "\n",
      "Epoch 97/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [08:18<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [08:13<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:59<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:59<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 97\n",
      "training_loss: 3.395  training_accuracy: 0.313  validation_loss: 3.5864 validation_accuracy: 0.145\n",
      "\n",
      "Epoch 98/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [08:42<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [09:17<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [02:11<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [02:10<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98\n",
      "training_loss: 3.3594  training_accuracy: 0.29  validation_loss: 3.6171 validation_accuracy: 0.14\n",
      "\n",
      "Epoch 99/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [09:02<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [09:01<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [02:11<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [02:10<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 99\n",
      "training_loss: 3.3429  training_accuracy: 0.309  validation_loss: 3.5873 validation_accuracy: 0.118\n",
      "\n",
      "Epoch 100/100\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [09:11<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving training accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [09:37<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [02:18<00:00,  1.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deriving validation accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [02:17<00:00,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100\n",
      "training_loss: 3.4528  training_accuracy: 0.282  validation_loss: 3.6277 validation_accuracy: 0.145\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "num_epochs = 100\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00001, weight_decay=1e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def accuracy(model, dataloader):\n",
    "      model.eval()\n",
    "      total_correct = 0\n",
    "      total_instances = 0\n",
    "      for frames, labels in tqdm(dataloader):\n",
    "        frames, labels = frames.to(device), labels.to(device)\n",
    "        predictions = torch.argmax(model(frames), dim=1)\n",
    "        correct_predictions = sum(predictions==labels).item()\n",
    "        total_correct+=correct_predictions\n",
    "        total_instances+=len(frames)\n",
    "      return round(total_correct/total_instances, 3)\n",
    "\n",
    "log_dict = {\n",
    "        'training_loss_per_batch': [],\n",
    "        'validation_loss_per_batch': [],\n",
    "        'training_accuracy_per_epoch': [],\n",
    "        'validation_accuracy_per_epoch': []\n",
    "    }\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "    train_losses = []\n",
    "    \n",
    "    # Training phase\n",
    "    model.train()\n",
    "    print('training...')\n",
    "    for frames, labels in tqdm(train_loader):\n",
    "        # Move your batches to the appropriate device\n",
    "        frames, labels = frames.to(device), labels.to(device)\n",
    "        # Forward pass, backward pass, and optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(frames)\n",
    "        loss = criterion(outputs, labels)\n",
    "        log_dict['training_loss_per_batch'].append(loss.item())\n",
    "        train_losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # Validation phase\n",
    "    with torch.no_grad():\n",
    "        print('deriving training accuracy...')\n",
    "        #  computing training accuracy\n",
    "        train_accuracy = accuracy(model, train_loader)\n",
    "        log_dict['training_accuracy_per_epoch'].append(train_accuracy)\n",
    "\n",
    "    print(\"validating...\")\n",
    "    val_losses = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for frames, labels in tqdm(val_loader):\n",
    "            frames, labels = frames.to(device), labels.to(device)\n",
    "            outputs = model(frames)\n",
    "            val_loss = criterion(outputs, labels)\n",
    "            log_dict['validation_loss_per_batch'].append(val_loss.item())\n",
    "            val_losses.append(val_loss.item())\n",
    "            # Compute validation loss, accuracy, etc.\n",
    "        print('deriving validation accuracy...')\n",
    "        val_accuracy = accuracy(model, val_loader)\n",
    "        log_dict['validation_accuracy_per_epoch'].append(val_accuracy)\n",
    "\n",
    "    train_losses = np.array(train_losses).mean()\n",
    "    val_losses = np.array(val_losses).mean()\n",
    "    print(\"epoch\",epoch+1)\n",
    "\n",
    "    print(f'training_loss: {round(train_losses, 4)}  training_accuracy: '+\n",
    "          f'{train_accuracy}  validation_loss: {round(val_losses, 4)} '+  \\\n",
    "          f'validation_accuracy: {val_accuracy}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd79c34-0122-4442-9adf-0b20c7fa254c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a77afb2-5ecd-4f4c-a1db-dec11fd5e498",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, r\"C:\\Users\\User\\Desktop\\project\\model\\handsign.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7fc09d7-f660-4253-8581-e129902370e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\.conda\\envs\\pytorchgpu\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from mobilenetv2 import MobileNetV2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "model = torch.load(r\"C:\\Users\\ACER\\Desktop\\python\\cnn\\best_modeltry.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b488dd9-8b96-4ed7-949c-6060d005d570",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64b8bf06-6c4d-47a0-b2dd-8ac76a3a87a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keys_from_value(dictionary, value):\n",
    "    keys = [key for key, val in dictionary.items() if val == value]\n",
    "    return keys\n",
    "    \n",
    "def frames_from_video_file(video_path, n_frames, target_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Extract frames from a video file.\n",
    "\n",
    "    Args:\n",
    "        video_path (str): Path to the video file.\n",
    "        n_frames (int): Number of frames to extract.\n",
    "\n",
    "    Returns:\n",
    "        list of numpy.ndarray: List of frames extracted from the video.\n",
    "    \"\"\"\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    if total_frames == 0:\n",
    "        return np.array(frames)  # Return empty list if no frames\n",
    "\n",
    "    # Calculate the indices of frames to extract\n",
    "    frame_indices = [int(i * total_frames / n_frames) for i in range(n_frames)]\n",
    "    \n",
    "    # Read frames at specified indices\n",
    "    for idx in frame_indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frame = cv2.resize(frame, target_size)\n",
    "            frame = np.transpose(frame, (2, 0, 1))\n",
    "            frames.append(frame)\n",
    "    \n",
    "    cap.release()\n",
    "    return np.array(frames).transpose(1,0,2,3)\n",
    "\n",
    "def MainModel():\n",
    "    folder_path = r\"C:\\Users\\ACER\\Desktop\\test_dataset\\sorted\"\n",
    "    correct = 0\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for filename in files:\n",
    "            if filename.endswith(\".mp4\"):\n",
    "                file_path = os.path.join(root, filename)\n",
    "                preprocessed_video = frames_from_video_file(file_path, 50)\n",
    "                preprocessed_video = torch.tensor(preprocessed_video, dtype=torch.float).to(device)\n",
    "                preprocessed_video = preprocessed_video.unsqueeze(0)\n",
    "                with torch.no_grad():\n",
    "                    predictions = model(preprocessed_video)\n",
    "                probabilities = torch.nn.functional.softmax(predictions, dim=1)\n",
    "                predicted_class = torch.argmax(probabilities, dim=1)\n",
    "                class_name = filename.split('_')[0]\n",
    "                predicted_class_name = get_keys_from_value(class_dict, predicted_class[0])\n",
    "                print(\"Class name:\", class_name)\n",
    "                print(\"Predicted class name:\", predicted_class_name)\n",
    "                if(class_name==predicted_class_name[0]):\n",
    "                    correct=correct+1\n",
    "    print(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbdc8ad-bb17-4b49-9999-52d4fe3e4d11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class name: a lot\n",
      "Predicted class name: ['a lot']\n",
      "Class name: a lot\n",
      "Predicted class name: ['and']\n",
      "Class name: abdomen\n",
      "Predicted class name: ['about']\n",
      "Class name: abdomen\n",
      "Predicted class name: ['active']\n",
      "Class name: able\n",
      "Predicted class name: ['able']\n",
      "Class name: able\n",
      "Predicted class name: ['announce']\n",
      "Class name: about\n",
      "Predicted class name: ['act']\n",
      "Class name: about\n",
      "Predicted class name: ['advantage']\n",
      "Class name: above\n",
      "Predicted class name: ['again']\n",
      "Class name: above\n",
      "Predicted class name: ['above']\n",
      "Class name: accent\n",
      "Predicted class name: ['and']\n",
      "Class name: accent\n",
      "Predicted class name: ['area']\n",
      "Class name: accept\n",
      "Predicted class name: ['afraid']\n",
      "Class name: accept\n",
      "Predicted class name: ['any']\n",
      "Class name: accident\n",
      "Predicted class name: ['aim']\n",
      "Class name: accident\n",
      "Predicted class name: ['analyze']\n",
      "Class name: accomplish\n",
      "Predicted class name: ['angel']\n",
      "Class name: accomplish\n",
      "Predicted class name: ['announce']\n",
      "Class name: accountant\n",
      "Predicted class name: ['around']\n",
      "Class name: accountant\n",
      "Predicted class name: ['alligator']\n",
      "Class name: across\n",
      "Predicted class name: ['army']\n",
      "Class name: across\n",
      "Predicted class name: ['announce']\n",
      "Class name: act\n",
      "Predicted class name: ['answer']\n",
      "Class name: act\n",
      "Predicted class name: ['admit']\n",
      "Class name: action\n",
      "Predicted class name: ['active']\n",
      "Class name: action\n",
      "Predicted class name: ['active']\n",
      "Class name: active\n",
      "Predicted class name: ['action']\n",
      "Class name: active\n",
      "Predicted class name: ['apart']\n",
      "Class name: activity\n",
      "Predicted class name: ['activity']\n",
      "Class name: activity\n",
      "Predicted class name: ['almost']\n",
      "Class name: actor\n",
      "Predicted class name: ['announce']\n",
      "Class name: actor\n",
      "Predicted class name: ['apart']\n",
      "Class name: adapt\n",
      "Predicted class name: ['a lot']\n",
      "Class name: adapt\n",
      "Predicted class name: ['appreciate']\n",
      "Class name: add\n",
      "Predicted class name: ['accountant']\n",
      "Class name: add\n",
      "Predicted class name: ['a lot']\n",
      "Class name: address\n",
      "Predicted class name: ['afraid']\n",
      "Class name: address\n",
      "Predicted class name: ['advantage']\n",
      "Class name: adjective\n",
      "Predicted class name: ['approach']\n",
      "Class name: adjective\n",
      "Predicted class name: ['approve']\n",
      "Class name: adjust\n",
      "Predicted class name: ['appropriate']\n",
      "Class name: adjust\n",
      "Predicted class name: ['artist']\n",
      "Class name: admire\n",
      "Predicted class name: ['advantage']\n",
      "Class name: admire\n",
      "Predicted class name: ['another']\n",
      "Class name: admit\n",
      "Predicted class name: ['army']\n",
      "Class name: admit\n",
      "Predicted class name: ['argue']\n",
      "Class name: adopt\n",
      "Predicted class name: ['adopt']\n",
      "Class name: adopt\n",
      "Predicted class name: ['activity']\n",
      "Class name: adult\n",
      "Predicted class name: ['accomplish']\n",
      "Class name: adult\n",
      "Predicted class name: ['ago']\n",
      "Class name: advanced\n",
      "Predicted class name: ['accomplish']\n",
      "Class name: advanced\n",
      "Predicted class name: ['accomplish']\n",
      "Class name: advantage\n",
      "Predicted class name: ['approach']\n",
      "Class name: advantage\n",
      "Predicted class name: ['activity']\n",
      "Class name: adverb\n",
      "Predicted class name: ['accountant']\n",
      "Class name: adverb\n",
      "Predicted class name: ['accomplish']\n",
      "Class name: affect\n",
      "Predicted class name: ['above']\n",
      "Class name: affect\n",
      "Predicted class name: ['article']\n",
      "Class name: afraid\n",
      "Predicted class name: ['activity']\n",
      "Class name: afraid\n",
      "Predicted class name: ['activity']\n",
      "Class name: africa\n",
      "Predicted class name: ['ago']\n",
      "Class name: africa\n",
      "Predicted class name: ['advanced']\n",
      "Class name: after\n",
      "Predicted class name: ['appreciate']\n",
      "Class name: after\n",
      "Predicted class name: ['against']\n",
      "Class name: afternoon\n",
      "Predicted class name: ['angel']\n",
      "Class name: afternoon\n",
      "Predicted class name: ['article']\n",
      "Class name: again\n",
      "Predicted class name: ['afraid']\n",
      "Class name: again\n",
      "Predicted class name: ['angry']\n",
      "Class name: against\n",
      "Predicted class name: ['agreement']\n",
      "Class name: against\n",
      "Predicted class name: ['allergy']\n",
      "Class name: age\n",
      "Predicted class name: ['army']\n",
      "Class name: age\n",
      "Predicted class name: ['accept']\n",
      "Class name: agenda\n",
      "Predicted class name: ['article']\n",
      "Class name: agenda\n",
      "Predicted class name: ['artist']\n",
      "Class name: ago\n",
      "Predicted class name: ['allergy']\n",
      "Class name: ago\n",
      "Predicted class name: ['apartment']\n",
      "Class name: agree\n",
      "Predicted class name: ['agree']\n",
      "Class name: agree\n",
      "Predicted class name: ['argue']\n",
      "Class name: agreement\n",
      "Predicted class name: ['agreement']\n",
      "Class name: agreement\n",
      "Predicted class name: ['argue']\n",
      "Class name: ahead\n",
      "Predicted class name: ['around']\n",
      "Class name: ahead\n",
      "Predicted class name: ['aid']\n",
      "Class name: aid\n",
      "Predicted class name: ['appropriate']\n",
      "Class name: aid\n",
      "Predicted class name: ['activity']\n",
      "Class name: aim\n",
      "Predicted class name: ['above']\n",
      "Class name: aim\n",
      "Predicted class name: ['accountant']\n",
      "Class name: airplane\n",
      "Predicted class name: ['arrogant']\n",
      "Class name: airplane\n",
      "Predicted class name: ['accomplish']\n",
      "Class name: alarm\n",
      "Predicted class name: ['aid']\n",
      "Class name: alarm\n",
      "Predicted class name: ['appropriate']\n",
      "Class name: alcohol\n",
      "Predicted class name: ['appointment']\n",
      "Class name: alcohol\n",
      "Predicted class name: ['action']\n",
      "Class name: algebra\n",
      "Predicted class name: ['around']\n",
      "Class name: algebra\n",
      "Predicted class name: ['appropriate']\n",
      "Class name: all\n",
      "Predicted class name: ['argue']\n",
      "Class name: all\n",
      "Predicted class name: ['aid']\n",
      "Class name: all day\n",
      "Predicted class name: ['all day']\n",
      "Class name: all day\n",
      "Predicted class name: ['all day']\n",
      "Class name: allergy\n",
      "Predicted class name: ['a lot']\n",
      "Class name: allergy\n",
      "Predicted class name: ['annoy']\n",
      "Class name: alligator\n",
      "Predicted class name: ['analyze']\n",
      "Class name: alligator\n",
      "Predicted class name: ['anatomy']\n",
      "Class name: allow\n",
      "Predicted class name: ['angry']\n",
      "Class name: allow\n",
      "Predicted class name: ['activity']\n",
      "Class name: almost\n",
      "Predicted class name: ['above']\n",
      "Class name: almost\n",
      "Predicted class name: ['accountant']\n",
      "Class name: alone\n",
      "Predicted class name: ['april']\n",
      "Class name: alone\n",
      "Predicted class name: ['america']\n",
      "Class name: alphabet\n",
      "Predicted class name: ['anniversary']\n",
      "Class name: alphabet\n",
      "Predicted class name: ['all day']\n",
      "Class name: already\n",
      "Predicted class name: ['allergy']\n",
      "Class name: already\n",
      "Predicted class name: ['allergy']\n",
      "Class name: also\n",
      "Predicted class name: ['activity']\n",
      "Class name: also\n",
      "Predicted class name: ['active']\n",
      "Class name: always\n",
      "Predicted class name: ['aid']\n",
      "Class name: always\n",
      "Predicted class name: ['against']\n",
      "Class name: amazing\n",
      "Predicted class name: ['animal']\n",
      "Class name: amazing\n",
      "Predicted class name: ['agree']\n",
      "Class name: america\n",
      "Predicted class name: ['around']\n",
      "Class name: america\n",
      "Predicted class name: ['against']\n",
      "Class name: amputate\n",
      "Predicted class name: ['affect']\n",
      "Class name: amputate\n",
      "Predicted class name: ['appetite']\n",
      "Class name: analyze\n",
      "Predicted class name: ['arrive']\n",
      "Class name: analyze\n",
      "Predicted class name: ['announce']\n",
      "Class name: anatomy\n",
      "Predicted class name: ['allow']\n",
      "Class name: anatomy\n",
      "Predicted class name: ['active']\n",
      "Class name: and\n",
      "Predicted class name: ['and']\n",
      "Class name: and\n",
      "Predicted class name: ['analyze']\n",
      "Class name: angel\n",
      "Predicted class name: ['announce']\n",
      "Class name: angel\n",
      "Predicted class name: ['angel']\n",
      "Class name: angle\n",
      "Predicted class name: ['angel']\n",
      "Class name: angle\n",
      "Predicted class name: ['appropriate']\n",
      "Class name: angry\n",
      "Predicted class name: ['afraid']\n",
      "Class name: angry\n",
      "Predicted class name: ['activity']\n",
      "Class name: animal\n",
      "Predicted class name: ['activity']\n",
      "Class name: animal\n",
      "Predicted class name: ['action']\n",
      "Class name: anniversary\n",
      "Predicted class name: ['accomplish']\n",
      "Class name: anniversary\n",
      "Predicted class name: ['angel']\n",
      "Class name: announce\n",
      "Predicted class name: ['announce']\n",
      "Class name: announce\n",
      "Predicted class name: ['allergy']\n",
      "Class name: annoy\n",
      "Predicted class name: ['agree']\n",
      "Class name: annoy\n",
      "Predicted class name: ['affect']\n",
      "Class name: another\n",
      "Predicted class name: ['angry']\n",
      "Class name: another\n",
      "Predicted class name: ['another']\n",
      "Class name: answer\n",
      "Predicted class name: ['anatomy']\n",
      "Class name: answer\n",
      "Predicted class name: ['agree']\n",
      "Class name: any\n",
      "Predicted class name: ['agreement']\n",
      "Class name: any\n",
      "Predicted class name: ['active']\n",
      "Class name: anyway\n",
      "Predicted class name: ['a lot']\n",
      "Class name: anyway\n",
      "Predicted class name: ['argue']\n",
      "Class name: apart\n",
      "Predicted class name: ['above']\n",
      "Class name: apart\n",
      "Predicted class name: ['activity']\n",
      "Class name: apartment\n",
      "Predicted class name: ['angel']\n",
      "Class name: apartment\n",
      "Predicted class name: ['any']\n",
      "Class name: apostrophe\n",
      "Predicted class name: ['apple']\n",
      "Class name: apostrophe\n",
      "Predicted class name: ['announce']\n",
      "Class name: appear\n",
      "Predicted class name: ['analyze']\n",
      "Class name: appear\n",
      "Predicted class name: ['already']\n",
      "Class name: appetite\n",
      "Predicted class name: ['admit']\n",
      "Class name: appetite\n",
      "Predicted class name: ['animal']\n",
      "Class name: apple\n",
      "Predicted class name: ['another']\n",
      "Class name: apple\n",
      "Predicted class name: ['afraid']\n",
      "Class name: appointment\n",
      "Predicted class name: ['article']\n",
      "Class name: appointment\n",
      "Predicted class name: ['around']\n",
      "Class name: appreciate\n",
      "Predicted class name: ['anatomy']\n",
      "Class name: appreciate\n",
      "Predicted class name: ['activity']\n",
      "Class name: approach\n",
      "Predicted class name: ['appointment']\n",
      "Class name: approach\n",
      "Predicted class name: ['approach']\n",
      "Class name: appropriate\n",
      "Predicted class name: ['appropriate']\n",
      "Class name: appropriate\n",
      "Predicted class name: ['area']\n",
      "Class name: approve\n",
      "Predicted class name: ['arrive']\n",
      "Class name: approve\n",
      "Predicted class name: ['anatomy']\n",
      "Class name: april\n",
      "Predicted class name: ['adverb']\n",
      "Class name: april\n",
      "Predicted class name: ['adverb']\n",
      "Class name: archery\n",
      "Predicted class name: ['article']\n",
      "Class name: archery\n",
      "Predicted class name: ['anyway']\n",
      "Class name: area\n",
      "Predicted class name: ['again']\n",
      "Class name: area\n",
      "Predicted class name: ['area']\n",
      "Class name: argue\n",
      "Predicted class name: ['appointment']\n"
     ]
    }
   ],
   "source": [
    "class_dict = {'a lot': 0, 'abdomen': 1, 'able': 2, 'about': 3, 'above': 4, 'accent': 5, 'accept': 6, 'accident': 7, 'accomplish': 8, 'accountant': 9, 'across': 10, 'act': 11, 'action': 12, 'active': 13, 'activity': 14, 'actor': 15, 'adapt': 16, 'add': 17, 'address': 18, 'adjective': 19, 'adjust': 20, 'admire': 21, 'admit': 22, 'adopt': 23, 'adult': 24, 'advanced': 25, 'advantage': 26, 'adverb': 27, 'affect': 28, 'afraid': 29, 'africa': 30, 'after': 31, 'afternoon': 32, 'again': 33, 'against': 34, 'age': 35, 'agenda': 36, 'ago': 37, 'agree': 38, 'agreement': 39, 'ahead': 40, 'aid': 41, 'aim': 42, 'airplane': 43, 'alarm': 44, 'alcohol': 45, 'algebra': 46, 'all': 47, 'all day': 48, 'allergy': 49, 'alligator': 50, 'allow': 51, 'almost': 52, 'alone': 53, 'alphabet': 54, 'already': 55, 'also': 56, 'always': 57, 'amazing': 58, 'america': 59, 'amputate': 60, 'analyze': 61, 'anatomy': 62, 'and': 63, 'angel': 64, 'angle': 65, 'angry': 66, 'animal': 67, 'anniversary': 68, 'announce': 69, 'annoy': 70, 'another': 71, 'answer': 72, 'any': 73, 'anyway': 74, 'apart': 75, 'apartment': 76, 'apostrophe': 77, 'appear': 78, 'appetite': 79, 'apple': 80, 'appointment': 81, 'appreciate': 82, 'approach': 83, 'appropriate': 84, 'approve': 85, 'april': 86, 'archery': 87, 'area': 88, 'argue': 89, 'arizona': 90, 'arm': 91, 'army': 92, 'around': 93, 'arrest': 94, 'arrive': 95, 'arrogant': 96, 'art': 97, 'article': 98, 'artist': 99}\n",
    "MainModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d404233f-7bd3-4fe1-b51e-9a94ca187d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_frames(frame, output_size):\n",
    "  \"\"\"\n",
    "    Pad and resize an image from a video.\n",
    "    \n",
    "    Args:\n",
    "      frame: Image that needs to resized and padded. \n",
    "      output_size: Pixel size of the output frame image.\n",
    "\n",
    "    Return:\n",
    "      Formatted frame with padding of specified output size.\n",
    "  \"\"\"\n",
    "  frame = tf.image.convert_image_dtype(frame, tf.float32)\n",
    "  frame = tf.image.resize_with_pad(frame, *output_size)\n",
    "  return frame\n",
    "def frames_from_video_file(video_path, n_frames, output_size = (224,224), frame_step = 1):\n",
    "  \"\"\"\n",
    "    Creates frames from each video file present for each category.\n",
    "\n",
    "    Args:\n",
    "      video_path: File path to the video.\n",
    "      n_frames: Number of frames to be created per video file.\n",
    "      output_size: Pixel size of the output frame image.\n",
    "\n",
    "    Return:\n",
    "      An NumPy array of frames in the shape of (n_frames, height, width, channels).\n",
    "  \"\"\"\n",
    "  # Read each video frame by frame\n",
    "  result = []\n",
    "  src = cv2.VideoCapture(str(video_path))  \n",
    "\n",
    "  video_length = src.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "\n",
    "  need_length = 1 + (n_frames - 1) * frame_step\n",
    "\n",
    "  if need_length > video_length:\n",
    "    start = 0\n",
    "  else:\n",
    "    max_start = video_length - need_length\n",
    "    start = random.randint(0, max_start + 1)\n",
    "\n",
    "  src.set(cv2.CAP_PROP_POS_FRAMES, start)\n",
    "  # ret is a boolean indicating whether read was successful, frame is the image itself\n",
    "  ret, frame = src.read()\n",
    "  result.append(format_frames(frame, output_size))\n",
    "\n",
    "  for _ in range(n_frames - 1):\n",
    "    for _ in range(frame_step):\n",
    "      ret, frame = src.read()\n",
    "    if ret:\n",
    "      frame = format_frames(frame, output_size)\n",
    "      result.append(frame)\n",
    "    else:\n",
    "      result.append(np.zeros_like(result[0]))\n",
    "  src.release()\n",
    "  result = np.array(result)[..., [2, 1, 0]]\n",
    "\n",
    "  return result\n",
    "def to_gif(images):\n",
    "  converted_images = np.clip(images * 255, 0, 255).astype(np.uint8)\n",
    "  imageio.mimsave('./animation.gif', converted_images, duration=20)\n",
    "  return embed.embed_file('./animation.gif')\n",
    "class FrameGenerator:\n",
    "  def __init__(self, path, n_frames, training = False):\n",
    "    \"\"\" Returns a set of frames with their associated label. \n",
    "\n",
    "      Args:\n",
    "        path: Video file paths.\n",
    "        n_frames: Number of frames. \n",
    "        training: Boolean to determine if training dataset is being created.\n",
    "    \"\"\"\n",
    "    self.path = path\n",
    "    self.n_frames = n_frames\n",
    "    self.training = training\n",
    "    self.class_names = sorted(set(p.name for p in self.path.iterdir() if p.is_dir()))\n",
    "    self.class_ids_for_name = dict((name, idx) for idx, name in enumerate(self.class_names))\n",
    "\n",
    "  def get_class_dictionary(self):\n",
    "    \"\"\"Returns a dictionary mapping class names to their corresponding class IDs.\"\"\"\n",
    "    return self.class_ids_for_name\n",
    "\n",
    "  def get_files_and_class_names(self):\n",
    "    video_paths = list(self.path.glob('*/*.mp4'))\n",
    "    classes = [p.parent.name for p in video_paths] \n",
    "    return video_paths, classes\n",
    "\n",
    "  def __call__(self):\n",
    "    video_paths, classes = self.get_files_and_class_names()\n",
    "\n",
    "    pairs = list(zip(video_paths, classes))\n",
    "\n",
    "    if self.training:\n",
    "      random.shuffle(pairs)\n",
    "\n",
    "    for path, name in pairs:\n",
    "      video_frames = frames_from_video_file(path, self.n_frames) \n",
    "      label = self.class_ids_for_name[name] # Encode labels\n",
    "      yield video_frames, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c099ba30-f05f-4758-98da-4d5452ab3c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "\n",
    "def frames_from_video_file(video_path, n_frames, target_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Extract frames from a video file.\n",
    "\n",
    "    Args:\n",
    "        video_path (str): Path to the video file.\n",
    "        n_frames (int): Number of frames to extract.\n",
    "\n",
    "    Returns:\n",
    "        list of numpy.ndarray: List of frames extracted from the video.\n",
    "    \"\"\"\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    if total_frames == 0:\n",
    "        return np.array(frames)  # Return empty list if no frames\n",
    "\n",
    "    # Calculate the indices of frames to extract\n",
    "    frame_indices = [int(i * total_frames / n_frames) for i in range(n_frames)]\n",
    "    \n",
    "    # Read frames at specified indices\n",
    "    for idx in frame_indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frame = cv2.resize(frame, target_size)\n",
    "            frame = np.transpose(frame, (2, 0, 1))\n",
    "            frames.append(frame)\n",
    "    \n",
    "    cap.release()\n",
    "    return np.array(frames).transpose(1,0,2,3)\n",
    "\n",
    "class FrameDataset(Dataset):\n",
    "    def __init__(self, path, n_frames, training=False):\n",
    "        \"\"\" Returns a set of frames with their associated label. \n",
    "\n",
    "        Args:\n",
    "            path: Video file paths.\n",
    "            n_frames: Number of frames. \n",
    "            training: Boolean to determine if training dataset is being created.\n",
    "        \"\"\"\n",
    "        self.path = path\n",
    "        self.n_frames = n_frames\n",
    "        self.training = training\n",
    "        self.class_names = sorted(set(p.name for p in self.path.iterdir() if p.is_dir()))\n",
    "        self.class_ids_for_name = dict((name, idx) for idx, name in enumerate(self.class_names))\n",
    "        self.video_paths, self.classes = self.get_files_and_class_names()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.video_paths[idx]\n",
    "        name = self.classes[idx]\n",
    "        video_frames = frames_from_video_file(path, self.n_frames)\n",
    "        label = self.class_ids_for_name[name]  # Encode labels\n",
    "        return torch.tensor(video_frames, dtype=torch.float), torch.tensor(label)\n",
    "\n",
    "    def get_files_and_class_names(self):\n",
    "        video_paths = list(self.path.glob('*/*.mp4'))\n",
    "        classes = [p.parent.name for p in video_paths] \n",
    "        if self.training:\n",
    "            random.seed(42)  # Set seed for reproducibility\n",
    "            random.shuffle(video_paths)\n",
    "            random.seed(42)  # Reset seed for shuffling classes\n",
    "            random.shuffle(classes)\n",
    "        return video_paths, classes\n",
    "\n",
    "    def get_class_dictionary(self):\n",
    "        \"\"\"Returns a dictionary mapping class names to their corresponding class IDs.\"\"\"\n",
    "        return self.class_ids_for_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f82d6ad-c35d-4d89-bed8-74f57dd46da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "# Initialize the datasets\n",
    "train_dataset = FrameDataset(subset_paths['train'], 50, training=True)\n",
    "val_dataset = FrameDataset(subset_paths['val'], 50, training=False)\n",
    "test_dataset = FrameDataset(subset_paths['test'], 50, training=False)\n",
    "\n",
    "# Create DataLoader instances\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d12b5e94-9485-41fe-ba46-4a7176bdac02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keys_from_value(dictionary, value):\n",
    "    keys = [key for key, val in dictionary.items() if val == value]\n",
    "    return keys\n",
    "\n",
    "def Hands(path):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    mpHands = mp.solutions.hands\n",
    "    hands = mpHands.Hands(max_num_hands=2,model_complexity=1, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "    mpDraw = mp.solutions.drawing_utils\n",
    "    handLandmarksStyle = mpDraw.DrawingSpec(color=(255, 0, 0), thickness=2)\n",
    "    handConnectionStyle = mpDraw.DrawingSpec(color=(0, 255, 0), thickness=3)\n",
    "    frame_width = int(cap.get(3))\n",
    "    frame_height = int(cap.get(4))\n",
    "    \n",
    "    classes = os.path.basename(path).split('.')[0]\n",
    "    out1 = cv2.VideoWriter(classes+'.mp4',cv2.VideoWriter_fourcc('M','P','4','V'), 10, (frame_width,frame_height))\n",
    "    while True:\n",
    "        ret, img = cap.read()\n",
    "        if ret:\n",
    "            imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            result = hands.process(imgRGB)\n",
    "                \n",
    "                #print(result.multi_hand_landmarks)\n",
    "            imgHeight = img.shape[0]\n",
    "            imgWidth = img.shape[1]\n",
    "                \n",
    "            frame1 = np.zeros((imgHeight, imgWidth, 3), dtype = np.uint8)\n",
    "                            \n",
    "            if result.multi_hand_landmarks:\n",
    "                for num, handLandmarks in enumerate(result.multi_hand_landmarks):\n",
    "                    mpDraw.draw_landmarks(frame1, handLandmarks, mpHands.HAND_CONNECTIONS, handLandmarksStyle, handConnectionStyle)\n",
    "                    out1.write(frame1)\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    out1.release()\n",
    "\n",
    "def preprocess_video_pytorch(video_path, target_frames=50, target_width=224, target_height=224):\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    frames = []\n",
    "    frame_count = 0\n",
    "    frame_counter = 0\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret or frame_count == target_frames:\n",
    "            break\n",
    "        \n",
    "        if frame_counter % 2 == 0:  # Adjust this condition based on your frame sampling rate\n",
    "            frame = cv2.resize(frame, (target_width, target_height))\n",
    "            frame = frame / 255.0  # Normalize pixel values\n",
    "            frame = frame.transpose((2, 0, 1))  # Change data layout from HWC to CHW for PyTorch\n",
    "            frames.append(frame)\n",
    "            frame_count += 1\n",
    "\n",
    "        frame_counter += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    # Padding if necessary to ensure all videos have the same frame count\n",
    "    while len(frames) < target_frames:\n",
    "        frames.append(np.zeros((3, target_height, target_width)))\n",
    "    \n",
    "    # Convert frames to a PyTorch tensor and add an extra dimension for batch size\n",
    "    frames = torch.tensor(frames).unsqueeze(0).float()  # Shape: (1, target_frames, 3, target_height, target_width)\n",
    "    \n",
    "    # Rearrange dimensions to match the expected input shape of the model: (batch, channels, frames, height, width)\n",
    "    frames = frames.permute(0, 2, 1, 3, 4)\n",
    "    \n",
    "    return frames\n",
    "\n",
    "def MainModel(path):\n",
    "    # Hands(path)\n",
    "    # video_path = os.path.basename(path).split('.')[0]+\".mp4\"\n",
    "    folder_path = r\"C:\\Users\\ACER\\Desktop\\test_dataset\\sorted\"\n",
    "    correct = 0\n",
    "    # Iterate over all files in the folder\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for filename in files:\n",
    "            # Check if the current file has the .mp4 extension\n",
    "            if filename.endswith(\".mp4\"):\n",
    "                # Construct the full file path\n",
    "                file_path = os.path.join(root, filename)\n",
    "                # Print the file path\n",
    "                # preprocessed_video = preprocess_video_pytorch(file_path).to(device)\n",
    "                preprocessed_video = frames_from_video_file(file_path, 50)\n",
    "                preprocessed_video = torch.tensor(preprocessed_video, dtype=torch.float).to(device)\n",
    "                preprocessed_video = preprocessed_video.unsqueeze(0)\n",
    "                with torch.no_grad():  # Disable gradient computation for inference\n",
    "                    predictions = model(preprocessed_video)\n",
    "                    # predictions will have the raw output from your model. You can then apply softmax if needed.\n",
    "                \n",
    "                # If your model's output is logits, apply softmax to get probabilities\n",
    "                probabilities = torch.nn.functional.softmax(predictions, dim=1)\n",
    "                predicted_class = torch.argmax(probabilities, dim=1)\n",
    "                # Process your predictions (e.g., take argmax for classification)\n",
    "                class_name = video_path.split('_')[0]\n",
    "                predicted_class_name = get_keys_from_value(class_dict, predicted_class[0])\n",
    "                print(\"Class name:\", filename.split('_')[0])\n",
    "                print(\"Predicted class name:\", predicted_class_name)\n",
    "                if(filename.split('_')[0]==predicted_class_name[0]):\n",
    "                    correct=correct+1\n",
    "    print(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8b114c22-dd40-4dea-bfab-7d3cc3d7cd08",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocessed_video' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 10\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01manimation\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01manimation\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Assuming preprocessed_video is a numpy array or similar for simplicity\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Let's pretend it has a shape like (1, 10, 3, 100, 100), meaning:\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# 1 video, 10 frames, 3 color channels, 100x100 pixels\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Simplify our example by removing the batch dimension if present\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m video \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocessed_video\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Function to update the plot for each frame\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_plot\u001b[39m(frame_number, video, plot):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'preprocessed_video' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "# Assuming preprocessed_video is a numpy array or similar for simplicity\n",
    "# Let's pretend it has a shape like (1, 10, 3, 100, 100), meaning:\n",
    "# 1 video, 10 frames, 3 color channels, 100x100 pixels\n",
    "\n",
    "# Simplify our example by removing the batch dimension if present\n",
    "video = preprocessed_video.squeeze(0)\n",
    "\n",
    "# Function to update the plot for each frame\n",
    "def update_plot(frame_number, video, plot):\n",
    "    plot.set_data(video[frame_number])\n",
    "\n",
    "# Create a figure for plotting\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Create an imshow object with the first frame of the video\n",
    "plot = plt.imshow(video[0], interpolation='nearest')\n",
    "\n",
    "# Create an animation\n",
    "ani = animation.FuncAnimation(fig, update_plot, frames=range(video.shape[0]), fargs=(video, plot))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a148293-40e7-4f48-a030-a01c81d4b667",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MainModelyay(path):\n",
    "    print(path)\n",
    "    video_path = os.path.basename(path).split('.')[0]\n",
    "    preprocessed_video = preprocess_video_pytorch(path)\n",
    "    model.eval()\n",
    "    with torch.no_grad():  # Disable gradient computation for inference\n",
    "        predictions = model(preprocessed_video)\n",
    "        # predictions will have the raw output from your model. You can then apply softmax if needed.\n",
    "    \n",
    "    # If your model's output is logits, apply softmax to get probabilities\n",
    "    probabilities = torch.nn.functional.softmax(predictions, dim=1)\n",
    "    print(probab\n",
    "    predicted_class = torch.argmax(probabilities, dim=1)\n",
    "    # Process your predictions (e.g., take argmax for classification)\n",
    "    class_name = video_path.split('_')[0]\n",
    "    print(\"Class name:\", class_name)\n",
    "    print(\"Predicted class name:\", predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "202f1677-1152-4e49-850a-2574147b9b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\Desktop\\test_dataset\\sorted\\a lot\\a lot_1.mp4\n",
      "Class name: a lot\n",
      "Predicted class name: tensor([21])\n",
      "C:\\Users\\ACER\\Desktop\\test_dataset\\sorted\\a lot\\a lot_5.mp4\n",
      "Class name: a lot\n",
      "Predicted class name: tensor([21])\n",
      "C:\\Users\\ACER\\Desktop\\test_dataset\\sorted\\abdomen\\abdomen_4.mp4\n",
      "Class name: abdomen\n",
      "Predicted class name: tensor([21])\n",
      "C:\\Users\\ACER\\Desktop\\test_dataset\\sorted\\abdomen\\abdomen_5.mp4\n",
      "Class name: abdomen\n",
      "Predicted class name: tensor([21])\n",
      "C:\\Users\\ACER\\Desktop\\test_dataset\\sorted\\able\\able_1.mp4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m video_files \u001b[38;5;241m=\u001b[39m get_video_files_recursive(path)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(video_files)):\n\u001b[1;32m---> 14\u001b[0m     \u001b[43mMainModelyay\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_files\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 4\u001b[0m, in \u001b[0;36mMainModelyay\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(path)\n\u001b[0;32m      3\u001b[0m video_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(path)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m----> 4\u001b[0m preprocessed_video \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_video_pytorch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():  \u001b[38;5;66;03m# Disable gradient computation for inference\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[4], line 67\u001b[0m, in \u001b[0;36mpreprocess_video_pytorch\u001b[1;34m(video_path, target_frames, target_width, target_height)\u001b[0m\n\u001b[0;32m     64\u001b[0m     frames\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m3\u001b[39m, target_height, target_width)))\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Convert frames to a PyTorch tensor and add an extra dimension for batch size\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m frames \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframes\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()  \u001b[38;5;66;03m# Shape: (1, target_frames, 3, target_height, target_width)\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# Rearrange dimensions to match the expected input shape of the model: (batch, channels, frames, height, width)\u001b[39;00m\n\u001b[0;32m     70\u001b[0m frames \u001b[38;5;241m=\u001b[39m frames\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class_dict = {'a lot': 0, 'abdomen': 1, 'able': 2, 'about': 3, 'above': 4, 'accent': 5, 'accept': 6, 'accident': 7, 'accomplish': 8, 'accountant': 9, 'across': 10, 'act': 11, 'action': 12, 'active': 13, 'activity': 14, 'actor': 15, 'adapt': 16, 'add': 17, 'address': 18, 'adjective': 19, 'adjust': 20, 'admire': 21, 'admit': 22, 'adopt': 23, 'adult': 24, 'advanced': 25, 'advantage': 26, 'adverb': 27, 'affect': 28, 'afraid': 29, 'africa': 30, 'after': 31, 'afternoon': 32, 'again': 33, 'against': 34, 'age': 35, 'agenda': 36, 'ago': 37, 'agree': 38, 'agreement': 39, 'ahead': 40, 'aid': 41, 'aim': 42, 'airplane': 43, 'alarm': 44, 'alcohol': 45, 'algebra': 46, 'all': 47, 'all day': 48, 'allergy': 49, 'alligator': 50, 'allow': 51, 'almost': 52, 'alone': 53, 'alphabet': 54, 'already': 55, 'also': 56, 'always': 57, 'amazing': 58, 'america': 59, 'amputate': 60, 'analyze': 61, 'anatomy': 62, 'and': 63, 'angel': 64, 'angle': 65, 'angry': 66, 'animal': 67, 'anniversary': 68, 'announce': 69, 'annoy': 70, 'another': 71, 'answer': 72, 'any': 73, 'anyway': 74, 'apart': 75, 'apartment': 76, 'apostrophe': 77, 'appear': 78, 'appetite': 79, 'apple': 80, 'appointment': 81, 'appreciate': 82, 'approach': 83, 'appropriate': 84, 'approve': 85, 'april': 86, 'archery': 87, 'area': 88, 'argue': 89, 'arizona': 90, 'arm': 91, 'army': 92, 'around': 93, 'arrest': 94, 'arrive': 95, 'arrogant': 96, 'art': 97, 'article': 98, 'artist': 99}\n",
    "path = r\"C:\\Users\\ACER\\Desktop\\test_dataset\\sorted\"\n",
    "def get_video_files_recursive(folder_path):\n",
    "    video_files = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".mp4\"):\n",
    "                video_files.append(os.path.join(root, file))\n",
    "    return video_files\n",
    "\n",
    "# Example usage\n",
    "video_files = get_video_files_recursive(path)\n",
    "for i in range(len(video_files)):\n",
    "    MainModelyay(video_files[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1688783-5a89-4d44-b1eb-4aaab9092196",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
